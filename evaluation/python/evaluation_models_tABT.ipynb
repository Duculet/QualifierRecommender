{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%aimport eval_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_methods = ['base', 'tOBT','tABT']\n",
    "experiments = ['FF', 'FT', 'TF', 'TT']\n",
    "results_dir = \"/Users/duculet/Thesis/NewWork/RecommenderServer/evalsets/lim_100/\"\n",
    "stats_dir = \"/Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/\"\n",
    "\n",
    "in_paths = generate_paths(results_dir, eval_methods, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_exp(eval_method, experiment, verbose=False):\n",
    "    # Setup paths and naming conventions\n",
    "    in_path = in_paths[eval_method][experiment]\n",
    "    out_path = stats_dir\n",
    "\n",
    "    # Generate models\n",
    "    models = generate_models(in_path, filelimit = 0, mintrans = 0, verbose = verbose)\n",
    "\n",
    "    # Exclude irrelevant models\n",
    "    excluded = ['P1855', 'P5192']\n",
    "    models_kept = [model for model in models if model.model_id not in excluded]\n",
    "    \n",
    "    # Generate name\n",
    "    name = eval_method + \"_\" + experiment\n",
    "\n",
    "    # sort models by trans count\n",
    "    models_by_trans = sorted(models_kept, key = lambda model: model.trans_count)\n",
    "\n",
    "    # compute statistics for each model, rank by trans count\n",
    "    stats_by_trans = []\n",
    "    for idx, model in enumerate(models_by_trans):\n",
    "        model_stats = model.get_statistics()\n",
    "        # add idx to model stats\n",
    "        model_stats['Pos'] = idx\n",
    "        # add model stats to list\n",
    "        stats_by_trans.append(model_stats)\n",
    "\n",
    "    # get the statistics for the entire experiment\n",
    "    experiment_stats = get_models_simple_stats(models_by_trans)\n",
    "\n",
    "    if verbose:\n",
    "        print(name)\n",
    "        print(experiment_stats)\n",
    "        print('-' * 20)\n",
    "\n",
    "    # convert list of series to dataframe and add experiment stats\n",
    "    statistics = pd.DataFrame(stats_by_trans)\n",
    "\n",
    "    # add experiment stats to dataframe and differentiate from models\n",
    "    experiment_stats = pd.DataFrame([experiment_stats], columns=statistics.columns)\n",
    "    experiment_stats['Pos'] = -1.0  # add negative index to differentiate from models\n",
    "\n",
    "    # concatenate models and experiment stats\n",
    "    statistics = pd.concat([experiment_stats, statistics]).reset_index(drop = True)\n",
    "\n",
    "    # save statistics\n",
    "    save_stats(out_path, name, statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1060/1060 [06:03<00:00,  2.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060 models generated\n",
      "tABT_FF\n",
      "Mean         1.8298\n",
      "Median       1.4887\n",
      "StdDev       1.1380\n",
      "Top1        70.7192\n",
      "Top5        96.2196\n",
      "Top10       98.6489\n",
      "Missing      0.0030\n",
      "Duration     0.0074\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FF_stats.csv\n",
      "FT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1061/1061 [05:36<00:00,  3.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061 models generated\n",
      "tABT_FT\n",
      "Mean         1.5738\n",
      "Median       1.3534\n",
      "StdDev       0.7794\n",
      "Top1        75.8690\n",
      "Top5        97.8243\n",
      "Top10       99.2349\n",
      "Missing      0.0031\n",
      "Duration     0.0276\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FT_stats.csv\n",
      "TF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1058/1058 [05:49<00:00,  3.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058 models generated\n",
      "tABT_TF\n",
      "Mean         1.6807\n",
      "Median       1.4261\n",
      "StdDev       0.8752\n",
      "Top1        73.6173\n",
      "Top5        97.1556\n",
      "Top10       98.9881\n",
      "Missing      0.0032\n",
      "Duration     0.0185\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TF_stats.csv\n",
      "TT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1059/1059 [05:59<00:00,  2.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059 models generated\n",
      "tABT_TT\n",
      "Mean         1.5293\n",
      "Median       1.3369\n",
      "StdDev       0.6823\n",
      "Top1        77.0860\n",
      "Top5        98.1101\n",
      "Top10       99.2896\n",
      "Missing      0.0031\n",
      "Duration     0.0356\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TT_stats.csv\n"
     ]
    }
   ],
   "source": [
    "eval_method = 'tABT'\n",
    "experiments = ['FF', 'FT', 'TF', 'TT']\n",
    "verbose = True\n",
    "\n",
    "# Run experiments\n",
    "for experiment in experiments:\n",
    "    print(experiment)\n",
    "    run_simple_exp(eval_method, experiment, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_stats(stats: pd.DataFrame) -> tuple[int, int, float, float, float, float]:\n",
    "    # compute total count for weighted averages\n",
    "    total_count = stats['Count'].sum()\n",
    "    # compute stats, weighted by counts in each group\n",
    "    avg_rank = (stats['Mean'] * stats['Count']).sum() / total_count\n",
    "    avg_rank = round(avg_rank, 4)\n",
    "    avg_top1 = (stats['Top1'] * stats['Count']).sum() / total_count\n",
    "    avg_top1 = round(avg_top1, 4)\n",
    "    avg_top5 = (stats['Top5'] * stats['Count']).sum() / total_count\n",
    "    avg_top5 = round(avg_top5, 4)\n",
    "    avg_top10 = (stats['Top10'] * stats['Count']).sum() / total_count\n",
    "    avg_top10 = round(avg_top10, 4)\n",
    "    # return stats\n",
    "    # return -1 to indicate these are group-wide stats\n",
    "    return -1, total_count, avg_rank, avg_top1, avg_top5, avg_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_statistics(stats: tuple[int, int, float, float, float, float]) -> None:\n",
    "    print(\"Total count: \" + str(stats[1]))\n",
    "    print(\"Average rank: \" + str(stats[2]))\n",
    "    print(\"Average top 1: \" + str(stats[3]))\n",
    "    print(\"Average top 5: \" + str(stats[4]))\n",
    "    print(\"Average top 10: \" + str(stats[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(eval_method: str, experiment: str, groupby: list[str] = None, verbose: bool = False):\n",
    "    # Setup paths and naming conventions\n",
    "    in_path = in_paths[eval_method][experiment]\n",
    "    out_path = stats_dir\n",
    "\n",
    "    # Generate models\n",
    "    models = generate_models(in_path, filelimit = 0, mintrans = 0, verbose = verbose)\n",
    "\n",
    "    # Exclude irrelevant models\n",
    "    excluded = ['P1855', 'P5192']\n",
    "    models_kept = [model for model in models if model.model_id not in excluded]\n",
    "\n",
    "    for group in groupby:\n",
    "        name = eval_method + \"_\" + experiment + \"_\" + group\n",
    "        # Generate stats\n",
    "        stats_complete = get_stats(models, group)\n",
    "        general_stats_complete = general_stats(stats_complete)\n",
    "\n",
    "        stats_relevant = get_stats(models_kept, group)\n",
    "        general_stats_relevant = general_stats(stats_relevant)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Statistics for \" + name)\n",
    "            print(\"All models\")\n",
    "            display_statistics(general_stats_complete)\n",
    "            # Print separator\n",
    "            print('-' * 20)\n",
    "            print(\"Relevant models\")\n",
    "            display_statistics(general_stats_relevant)\n",
    "\n",
    "        # Update stats with general stats as first row\n",
    "        new_stats = pd.DataFrame([general_stats_relevant], columns=stats_relevant.columns)\n",
    "        stats_relevant = pd.concat([new_stats, stats_relevant]).reset_index(drop=True)\n",
    "        # Save stats\n",
    "        save_stats(out_path, name, stats_relevant)\n",
    "\n",
    "        # Print separator\n",
    "        print(\"#\" * 20)\n",
    "    \n",
    "    # free memory\n",
    "    del models\n",
    "    del models_kept\n",
    "    del stats_complete\n",
    "    del stats_relevant\n",
    "    del general_stats_complete\n",
    "    del general_stats_relevant\n",
    "    del new_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "eval_method = 'base'\n",
    "experiment = 'TT' # doesn't matter in this case\n",
    "groupby = ['SetSize', 'NumNonTypes', 'NumTypes', 'NumObjTypes', 'NumSubjTypes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/1059 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1059/1059 [04:08<00:00,  4.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059 models generated\n",
      "Statistics for base_TT_SetSize\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumNonTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumObjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumSubjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take All But Type evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_method = 'tABT'\n",
    "groupby = ['SetSize', 'NumNonTypes', 'NumTypes', 'NumObjTypes', 'NumSubjTypes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No type information (FF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup and generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'FF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1060/1060 [04:24<00:00,  4.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060 models generated\n",
      "Statistics for tABT_FF_SetSize\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 7.0102\n",
      "Average top 1: 70.6528\n",
      "Average top 5: 96.1296\n",
      "Average top 10: 98.557\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 1.8298\n",
      "Average top 1: 70.7192\n",
      "Average top 5: 96.2196\n",
      "Average top 10: 98.6489\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FF_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FF_NumNonTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 7.0102\n",
      "Average top 1: 70.6528\n",
      "Average top 5: 96.1296\n",
      "Average top 10: 98.557\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 1.8298\n",
      "Average top 1: 70.7192\n",
      "Average top 5: 96.2196\n",
      "Average top 10: 98.6489\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FF_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FF_NumTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 7.0102\n",
      "Average top 1: 70.6528\n",
      "Average top 5: 96.1296\n",
      "Average top 10: 98.557\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 1.8298\n",
      "Average top 1: 70.7192\n",
      "Average top 5: 96.2196\n",
      "Average top 10: 98.6489\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FF_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FF_NumObjTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 7.0102\n",
      "Average top 1: 70.6528\n",
      "Average top 5: 96.1296\n",
      "Average top 10: 98.557\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 1.8298\n",
      "Average top 1: 70.7192\n",
      "Average top 5: 96.2196\n",
      "Average top 10: 98.6489\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FF_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FF_NumSubjTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 7.0102\n",
      "Average top 1: 70.6528\n",
      "Average top 5: 96.1296\n",
      "Average top 10: 98.557\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 1.8298\n",
      "Average top 1: 70.7192\n",
      "Average top 5: 96.2196\n",
      "Average top 10: 98.6489\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FF_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only object type information (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'TF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1058/1058 [04:21<00:00,  4.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058 models generated\n",
      "Statistics for tABT_TF_SetSize\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.5249\n",
      "Average top 1: 72.3681\n",
      "Average top 5: 96.6515\n",
      "Average top 10: 98.6686\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.748\n",
      "Average top 1: 72.5039\n",
      "Average top 5: 96.8268\n",
      "Average top 10: 98.8426\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TF_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TF_NumNonTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.5108\n",
      "Average top 1: 73.4832\n",
      "Average top 5: 96.9844\n",
      "Average top 10: 98.8186\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.6807\n",
      "Average top 1: 73.6173\n",
      "Average top 5: 97.1556\n",
      "Average top 10: 98.9881\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TF_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TF_NumTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.5249\n",
      "Average top 1: 72.3681\n",
      "Average top 5: 96.6515\n",
      "Average top 10: 98.6686\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.748\n",
      "Average top 1: 72.5039\n",
      "Average top 5: 96.8268\n",
      "Average top 10: 98.8426\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TF_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TF_NumObjTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.5249\n",
      "Average top 1: 72.3681\n",
      "Average top 5: 96.6515\n",
      "Average top 10: 98.6686\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.748\n",
      "Average top 1: 72.5039\n",
      "Average top 5: 96.8268\n",
      "Average top 10: 98.8426\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TF_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TF_NumSubjTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.5108\n",
      "Average top 1: 73.4832\n",
      "Average top 5: 96.9844\n",
      "Average top 10: 98.8186\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.6807\n",
      "Average top 1: 73.6173\n",
      "Average top 5: 97.1556\n",
      "Average top 10: 98.9881\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TF_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only subject type information (FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'FT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1061/1061 [04:21<00:00,  4.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061 models generated\n",
      "Statistics for tABT_FT_SetSize\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.8305\n",
      "Average top 1: 75.2064\n",
      "Average top 5: 97.5367\n",
      "Average top 10: 99.0496\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.6022\n",
      "Average top 1: 75.34\n",
      "Average top 5: 97.6918\n",
      "Average top 10: 99.1947\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FT_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FT_NumNonTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.7101\n",
      "Average top 1: 75.7561\n",
      "Average top 5: 97.7019\n",
      "Average top 10: 99.1308\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.5738\n",
      "Average top 1: 75.869\n",
      "Average top 5: 97.8243\n",
      "Average top 10: 99.2349\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FT_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FT_NumTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.8305\n",
      "Average top 1: 75.2064\n",
      "Average top 5: 97.5367\n",
      "Average top 10: 99.0496\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.6022\n",
      "Average top 1: 75.34\n",
      "Average top 5: 97.6918\n",
      "Average top 10: 99.1947\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FT_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FT_NumObjTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.7101\n",
      "Average top 1: 75.7561\n",
      "Average top 5: 97.7019\n",
      "Average top 10: 99.1308\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.5738\n",
      "Average top 1: 75.869\n",
      "Average top 5: 97.8243\n",
      "Average top 10: 99.2349\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FT_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_FT_NumSubjTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.8305\n",
      "Average top 1: 75.2064\n",
      "Average top 5: 97.5367\n",
      "Average top 10: 99.0496\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.6022\n",
      "Average top 1: 75.34\n",
      "Average top 5: 97.6918\n",
      "Average top 10: 99.1947\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_FT_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both subject and object type information (TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'TT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1059/1059 [04:29<00:00,  3.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059 models generated\n",
      "Statistics for tABT_TT_SetSize\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.7582\n",
      "Average top 1: 75.7317\n",
      "Average top 5: 97.5522\n",
      "Average top 10: 99.0001\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.5923\n",
      "Average top 1: 75.8613\n",
      "Average top 5: 97.6952\n",
      "Average top 10: 99.132\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TT_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TT_NumNonTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.7143\n",
      "Average top 1: 76.9725\n",
      "Average top 5: 97.9913\n",
      "Average top 10: 99.1891\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.5293\n",
      "Average top 1: 77.086\n",
      "Average top 5: 98.1101\n",
      "Average top 10: 99.2896\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TT_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TT_NumTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.7582\n",
      "Average top 1: 75.7317\n",
      "Average top 5: 97.5522\n",
      "Average top 10: 99.0001\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.5923\n",
      "Average top 1: 75.8613\n",
      "Average top 5: 97.6952\n",
      "Average top 10: 99.132\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TT_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TT_NumObjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.6551\n",
      "Average top 1: 76.1776\n",
      "Average top 5: 97.623\n",
      "Average top 10: 99.0066\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.5847\n",
      "Average top 1: 76.2913\n",
      "Average top 5: 97.7425\n",
      "Average top 10: 99.1077\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TT_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tABT_TT_NumSubjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 3.1946\n",
      "Average top 1: 76.1776\n",
      "Average top 5: 97.6768\n",
      "Average top 10: 98.9998\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.5789\n",
      "Average top 1: 76.3084\n",
      "Average top 5: 97.8214\n",
      "Average top 10: 99.1338\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tABT_TT_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
