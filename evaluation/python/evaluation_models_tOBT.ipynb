{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%aimport eval_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_methods = ['base', 'tOBT','tABT']\n",
    "experiments = ['FF', 'FT', 'TF', 'TT']\n",
    "results_dir = \"/Users/duculet/Thesis/NewWork/RecommenderServer/evalsets/lim_100/\"\n",
    "stats_dir = \"/Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/\"\n",
    "\n",
    "in_paths = generate_paths(results_dir, eval_methods, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_exp(eval_method, experiment, verbose=False):\n",
    "    # Setup paths and naming conventions\n",
    "    in_path = in_paths[eval_method][experiment]\n",
    "    out_path = stats_dir\n",
    "\n",
    "    # Generate models\n",
    "    models = generate_models(in_path, filelimit = 0, mintrans = 0, verbose = verbose)\n",
    "\n",
    "    # Exclude irrelevant models\n",
    "    excluded = ['P1855', 'P5192']\n",
    "    models_kept = [model for model in models if model.model_id not in excluded]\n",
    "    \n",
    "    # Generate name\n",
    "    name = eval_method + \"_\" + experiment\n",
    "\n",
    "    # sort models by trans count\n",
    "    models_by_trans = sorted(models_kept, key = lambda model: model.trans_count)\n",
    "\n",
    "    # compute statistics for each model, rank by trans count\n",
    "    stats_by_trans = []\n",
    "    for idx, model in enumerate(models_by_trans):\n",
    "        model_stats = model.get_statistics() \n",
    "        # add idx to model stats\n",
    "        model_stats['Pos'] = idx\n",
    "        # add model stats to list\n",
    "        stats_by_trans.append(model_stats)\n",
    "\n",
    "    # get the statistics for the entire experiment\n",
    "    experiment_stats = get_models_simple_stats(models_by_trans)\n",
    "\n",
    "    if verbose:\n",
    "        print(name)\n",
    "        print(experiment_stats)\n",
    "        print('-' * 20)\n",
    "\n",
    "    # convert list of series to dataframe and add experiment stats\n",
    "    statistics = pd.DataFrame(stats_by_trans)\n",
    "\n",
    "    # add experiment stats to dataframe and differentiate from models\n",
    "    experiment_stats = pd.DataFrame([experiment_stats], columns=statistics.columns)\n",
    "    experiment_stats['Pos'] = -1.0  # add negative index to differentiate from models\n",
    "\n",
    "    # concatenate models and experiment stats\n",
    "    statistics = pd.concat([experiment_stats, statistics]).reset_index(drop = True)\n",
    "\n",
    "    # save statistics\n",
    "    save_stats(out_path, name, statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1060/1060 [05:30<00:00,  3.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060 models generated\n",
      "tOBT_FF\n",
      "Mean         5.1816\n",
      "Median       3.1143\n",
      "StdDev       7.0066\n",
      "Top1        52.6749\n",
      "Top5        77.4949\n",
      "Top10       87.8853\n",
      "Missing      0.0030\n",
      "Duration     0.0092\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FF_stats.csv\n",
      "FT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1061/1061 [05:43<00:00,  3.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061 models generated\n",
      "tOBT_FT\n",
      "Mean         1.3535\n",
      "Median       1.0812\n",
      "StdDev       0.6670\n",
      "Top1        89.7055\n",
      "Top5        98.2256\n",
      "Top10       99.3074\n",
      "Missing      0.0031\n",
      "Duration     0.0364\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FT_stats.csv\n",
      "TF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1058/1058 [05:18<00:00,  3.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058 models generated\n",
      "tOBT_TF\n",
      "Mean         1.4301\n",
      "Median       1.0972\n",
      "StdDev       0.7393\n",
      "Top1        87.6284\n",
      "Top5        97.8587\n",
      "Top10       99.1271\n",
      "Missing      0.0032\n",
      "Duration     0.0237\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TF_stats.csv\n",
      "TT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1059/1059 [04:30<00:00,  3.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059 models generated\n",
      "tOBT_TT\n",
      "Mean         1.3132\n",
      "Median       1.0666\n",
      "StdDev       0.5918\n",
      "Top1        91.1623\n",
      "Top5        98.4774\n",
      "Top10       99.3390\n",
      "Missing      0.0031\n",
      "Duration     0.0474\n",
      "dtype: float64\n",
      "--------------------\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TT_stats.csv\n"
     ]
    }
   ],
   "source": [
    "eval_method = 'tOBT'\n",
    "experiments = ['FF', 'FT', 'TF', 'TT']\n",
    "verbose = True\n",
    "\n",
    "# Run experiments\n",
    "for experiment in experiments:\n",
    "    print(experiment)\n",
    "    run_simple_exp(eval_method, experiment, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_stats(stats: pd.DataFrame) -> tuple[int, int, float, float, float, float]:\n",
    "    # compute total count for weighted averages\n",
    "    total_count = stats['Count'].sum()\n",
    "    # compute stats, weighted by counts in each group\n",
    "    avg_rank = (stats['Mean'] * stats['Count']).sum() / total_count\n",
    "    avg_rank = round(avg_rank, 4)\n",
    "    avg_top1 = (stats['Top1'] * stats['Count']).sum() / total_count\n",
    "    avg_top1 = round(avg_top1, 4)\n",
    "    avg_top5 = (stats['Top5'] * stats['Count']).sum() / total_count\n",
    "    avg_top5 = round(avg_top5, 4)\n",
    "    avg_top10 = (stats['Top10'] * stats['Count']).sum() / total_count\n",
    "    avg_top10 = round(avg_top10, 4)\n",
    "    # return stats\n",
    "    # return -1 to indicate these are group-wide stats\n",
    "    return -1, total_count, avg_rank, avg_top1, avg_top5, avg_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_statistics(stats: tuple[int, int, float, float, float, float]) -> None:\n",
    "    print(\"Total count: \" + str(stats[1]))\n",
    "    print(\"Average rank: \" + str(stats[2]))\n",
    "    print(\"Average top 1: \" + str(stats[3]))\n",
    "    print(\"Average top 5: \" + str(stats[4]))\n",
    "    print(\"Average top 10: \" + str(stats[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(eval_method: str, experiment: str, groupby: list[str] = None, verbose: bool = False):\n",
    "    # Setup paths and naming conventions\n",
    "    in_path = in_paths[eval_method][experiment]\n",
    "    out_path = stats_dir\n",
    "\n",
    "    # Generate models\n",
    "    models = generate_models(in_path, filelimit = 0, mintrans = 0, verbose = verbose)\n",
    "\n",
    "    # Exclude irrelevant models\n",
    "    excluded = ['P1855', 'P5192']\n",
    "    models_kept = [model for model in models if model.model_id not in excluded]\n",
    "\n",
    "    for group in groupby:\n",
    "        name = eval_method + \"_\" + experiment + \"_\" + group\n",
    "        # Generate stats\n",
    "        stats_complete = get_stats(models, group)\n",
    "        general_stats_complete = general_stats(stats_complete)\n",
    "\n",
    "        stats_relevant = get_stats(models_kept, group)\n",
    "        general_stats_relevant = general_stats(stats_relevant)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Statistics for \" + name)\n",
    "            print(\"All models\")\n",
    "            display_statistics(general_stats_complete)\n",
    "            # Print separator\n",
    "            print('-' * 20)\n",
    "            print(\"Relevant models\")\n",
    "            display_statistics(general_stats_relevant)\n",
    "\n",
    "        # Update stats with general stats as first row\n",
    "        new_stats = pd.DataFrame([general_stats_relevant], columns=stats_relevant.columns)\n",
    "        stats_relevant = pd.concat([new_stats, stats_relevant]).reset_index(drop=True)\n",
    "        # Save stats\n",
    "        save_stats(out_path, name, stats_relevant)\n",
    "\n",
    "        # Print separator\n",
    "        print(\"#\" * 20)\n",
    "    \n",
    "    # free memory\n",
    "    del models\n",
    "    del models_kept\n",
    "    del stats_complete\n",
    "    del stats_relevant\n",
    "    del general_stats_complete\n",
    "    del general_stats_relevant\n",
    "    del new_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "eval_method = 'base'\n",
    "experiment = 'TT' # doesn't matter in this case\n",
    "groupby = ['SetSize', 'NumNonTypes', 'NumTypes', 'NumObjTypes', 'NumSubjTypes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/1059 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1059/1059 [04:18<00:00,  4.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059 models generated\n",
      "Statistics for base_TT_SetSize\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumNonTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumObjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for base_TT_NumSubjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 7.1568\n",
      "Average top 1: 70.5497\n",
      "Average top 5: 96.0294\n",
      "Average top 10: 98.4445\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.832\n",
      "Average top 1: 70.6825\n",
      "Average top 5: 96.2079\n",
      "Average top 10: 98.6246\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/base_TT_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take One But Type evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_method = 'tOBT'\n",
    "groupby = ['SetSize', 'NumNonTypes', 'NumTypes', 'NumObjTypes', 'NumSubjTypes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No type information (FF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup and generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'FF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1060/1060 [04:21<00:00,  4.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060 models generated\n",
      "Statistics for tOBT_FF_SetSize\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 11.6136\n",
      "Average top 1: 38.7296\n",
      "Average top 5: 69.6657\n",
      "Average top 10: 83.3747\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 6.6764\n",
      "Average top 1: 38.7625\n",
      "Average top 5: 69.7273\n",
      "Average top 10: 83.449\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FF_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FF_NumNonTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 11.6136\n",
      "Average top 1: 38.7296\n",
      "Average top 5: 69.6657\n",
      "Average top 10: 83.3747\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 6.6764\n",
      "Average top 1: 38.7625\n",
      "Average top 5: 69.7273\n",
      "Average top 10: 83.449\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FF_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FF_NumTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 10.2842\n",
      "Average top 1: 52.6277\n",
      "Average top 5: 77.4249\n",
      "Average top 10: 87.8058\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 5.1816\n",
      "Average top 1: 52.6749\n",
      "Average top 5: 77.4949\n",
      "Average top 10: 87.8853\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FF_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FF_NumObjTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 10.2842\n",
      "Average top 1: 52.6277\n",
      "Average top 5: 77.4249\n",
      "Average top 10: 87.8058\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 5.1816\n",
      "Average top 1: 52.6749\n",
      "Average top 5: 77.4949\n",
      "Average top 10: 87.8853\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FF_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FF_NumSubjTypes\n",
      "All models\n",
      "Total count: 56253705\n",
      "Average rank: 10.2842\n",
      "Average top 1: 52.6277\n",
      "Average top 5: 77.4249\n",
      "Average top 10: 87.8058\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56248238\n",
      "Average rank: 5.1816\n",
      "Average top 1: 52.6749\n",
      "Average top 5: 77.4949\n",
      "Average top 10: 87.8853\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FF_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only object type information (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'TF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1058/1058 [04:32<00:00,  3.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058 models generated\n",
      "Statistics for tOBT_TF_SetSize\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.627\n",
      "Average top 1: 80.6691\n",
      "Average top 5: 96.218\n",
      "Average top 10: 98.453\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.7126\n",
      "Average top 1: 80.8215\n",
      "Average top 5: 96.39\n",
      "Average top 10: 98.6257\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TF_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TF_NumNonTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.471\n",
      "Average top 1: 81.6449\n",
      "Average top 5: 96.4135\n",
      "Average top 10: 98.503\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.6753\n",
      "Average top 1: 81.7936\n",
      "Average top 5: 96.5797\n",
      "Average top 10: 98.6695\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TF_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TF_NumTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.2392\n",
      "Average top 1: 86.3604\n",
      "Average top 5: 97.4175\n",
      "Average top 10: 98.8188\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.4924\n",
      "Average top 1: 86.5177\n",
      "Average top 5: 97.5891\n",
      "Average top 10: 98.9892\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TF_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TF_NumObjTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.2392\n",
      "Average top 1: 86.3604\n",
      "Average top 5: 97.4175\n",
      "Average top 10: 98.8188\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.4924\n",
      "Average top 1: 86.5177\n",
      "Average top 5: 97.5891\n",
      "Average top 10: 98.9892\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TF_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TF_NumSubjTypes\n",
      "All models\n",
      "Total count: 56260835\n",
      "Average rank: 4.2331\n",
      "Average top 1: 87.4735\n",
      "Average top 5: 97.6913\n",
      "Average top 10: 98.9609\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56255219\n",
      "Average rank: 1.4301\n",
      "Average top 1: 87.6284\n",
      "Average top 5: 97.8587\n",
      "Average top 10: 99.1271\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TF_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only subject type information (FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'FT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/1061 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1061/1061 [04:33<00:00,  3.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061 models generated\n",
      "Statistics for tOBT_FT_SetSize\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.6961\n",
      "Average top 1: 85.8374\n",
      "Average top 5: 97.4289\n",
      "Average top 10: 98.854\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.4836\n",
      "Average top 1: 85.9875\n",
      "Average top 5: 97.5791\n",
      "Average top 10: 98.9947\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FT_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FT_NumNonTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.7285\n",
      "Average top 1: 84.4403\n",
      "Average top 5: 97.1421\n",
      "Average top 10: 98.7789\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.5484\n",
      "Average top 1: 84.5569\n",
      "Average top 5: 97.2537\n",
      "Average top 10: 98.8765\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FT_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FT_NumTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.6025\n",
      "Average top 1: 89.1355\n",
      "Average top 5: 98.0043\n",
      "Average top 10: 99.1323\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.3757\n",
      "Average top 1: 89.2891\n",
      "Average top 5: 98.1556\n",
      "Average top 10: 99.2752\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FT_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FT_NumObjTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.4891\n",
      "Average top 1: 89.5719\n",
      "Average top 5: 98.1071\n",
      "Average top 10: 99.2049\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.3535\n",
      "Average top 1: 89.7055\n",
      "Average top 5: 98.2256\n",
      "Average top 10: 99.3074\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FT_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_FT_NumSubjTypes\n",
      "All models\n",
      "Total count: 56253327\n",
      "Average rank: 1.6025\n",
      "Average top 1: 89.1355\n",
      "Average top 5: 98.0043\n",
      "Average top 10: 99.1323\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56247608\n",
      "Average rank: 1.3757\n",
      "Average top 1: 89.2891\n",
      "Average top 5: 98.1556\n",
      "Average top 10: 99.2752\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_FT_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both subject and object type information (TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "experiment = 'TT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1059/1059 [06:04<00:00,  2.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059 models generated\n",
      "Statistics for tOBT_TT_SetSize\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.6571\n",
      "Average top 1: 87.0073\n",
      "Average top 5: 97.5135\n",
      "Average top 10: 98.8718\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.4673\n",
      "Average top 1: 87.1557\n",
      "Average top 5: 97.6551\n",
      "Average top 10: 99.0048\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TT_SetSize_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TT_NumNonTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.6982\n",
      "Average top 1: 86.5911\n",
      "Average top 5: 97.4748\n",
      "Average top 10: 98.8784\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.4855\n",
      "Average top 1: 86.7114\n",
      "Average top 5: 97.5852\n",
      "Average top 10: 98.9749\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TT_NumNonTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TT_NumTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.518\n",
      "Average top 1: 89.8828\n",
      "Average top 5: 97.9609\n",
      "Average top 10: 99.0421\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.3721\n",
      "Average top 1: 90.0239\n",
      "Average top 5: 98.0929\n",
      "Average top 10: 99.1664\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TT_NumTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TT_NumObjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.4274\n",
      "Average top 1: 90.1718\n",
      "Average top 5: 98.0237\n",
      "Average top 10: 99.0629\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.3666\n",
      "Average top 1: 90.3015\n",
      "Average top 5: 98.1358\n",
      "Average top 10: 99.16\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TT_NumObjTypes_stats.csv\n",
      "####################\n",
      "Statistics for tOBT_TT_NumSubjTypes\n",
      "All models\n",
      "Total count: 56262350\n",
      "Average rank: 2.9555\n",
      "Average top 1: 90.3209\n",
      "Average top 5: 98.0778\n",
      "Average top 10: 99.0439\n",
      "--------------------\n",
      "Relevant models\n",
      "Total count: 56256548\n",
      "Average rank: 1.3596\n",
      "Average top 1: 90.4629\n",
      "Average top 5: 98.2112\n",
      "Average top 10: 99.17\n",
      "Saved results to /Users/duculet/Thesis/NewWork/RecommenderServer/evaluation/python/statistics/full/tOBT_TT_NumSubjTypes_stats.csv\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "run_experiment(eval_method, experiment, groupby, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
